{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydDT3oL-c5d8"
      },
      "source": [
        "# Training an N-Gram Language Model Using KenLM Software"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TJqNBOtXm9mE",
        "outputId": "c71dff02-02ab-4ce2-a2d6-d4ab890e6ede"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount your Google Drive to copy the clean data from\n",
        "import sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "experiment_folder = '/content/drive/My Drive/my_projects/PSU_language_models_session/'\n",
        "sys.path.append(experiment_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hlQmcbT_n7qq"
      },
      "outputs": [],
      "source": [
        "# change the paths below to fit your needs. They should be the paths that you\n",
        "# used them in notebook #1 (1- Prepare Data.ipynb)\n",
        "!cp '/content/drive/My Drive/my_projects/PSU_language_models_session/data/Clean_Ryiadh_text.txt' /content/Clean_Ryiadh_text.txt\n",
        "!cp '/content/drive/My Drive/my_projects/PSU_language_models_session/data/Clean_SaudiYoum_text.txt' /content/Clean_SaudiYoum_text.txt\n",
        "!cp '/content/drive/My Drive/my_projects/PSU_language_models_session/data/vocab_list.txt' /content/vocab_list.txt\n",
        "!cat /content/Clean_SaudiYoum_text.txt /content/Clean_Ryiadh_text.txt > /content/Clean_SaudiYoum_n_Ryiadh_text.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T6Q5X5lr1Vz",
        "outputId": "eb2d2bf2-6463-4d74-dce2-65d3f0ff98a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'eigen'...\n",
            "remote: Enumerating objects: 117036, done.\u001b[K\n",
            "remote: Counting objects: 100% (129/129), done.\u001b[K\n",
            "remote: Compressing objects: 100% (82/82), done.\u001b[K\n",
            "remote: Total 117036 (delta 67), reused 102 (delta 47), pack-reused 116907\u001b[K\n",
            "Receiving objects: 100% (117036/117036), 102.59 MiB | 21.19 MiB/s, done.\n",
            "Resolving deltas: 100% (96642/96642), done.\n"
          ]
        }
      ],
      "source": [
        "# This library is a prerequisite for KenLM language model builder\n",
        "!git clone https://gitlab.com/libeigen/eigen.git\n",
        "!export EIGEN3_ROOT=$HOME/eigen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f137iKYyr1bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcdfdec5-9861-4570-f4c6-faef9de67545"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2022-09-17 20:10:11--  https://kheafield.com/code/kenlm.tar.gz\n",
            "Resolving kheafield.com (kheafield.com)... 35.196.63.85\n",
            "Connecting to kheafield.com (kheafield.com)|35.196.63.85|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 491888 (480K) [application/x-gzip]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>] 480.36K  2.72MB/s    in 0.2s    \n",
            "\n",
            "2022-09-17 20:10:11 (2.72 MB/s) - written to stdout [491888/491888]\n",
            "\n",
            "/content/kenlm/build\n",
            "-- The C compiler identification is GNU 7.5.0\n",
            "-- The CXX compiler identification is GNU 7.5.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "-- Could NOT find Eigen3 (missing: Eigen3_DIR)\n",
            "-- Looking for pthread.h\n",
            "-- Looking for pthread.h - found\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD\n",
            "-- Performing Test CMAKE_HAVE_LIBC_PTHREAD - Failed\n",
            "-- Looking for pthread_create in pthreads\n",
            "-- Looking for pthread_create in pthreads - not found\n",
            "-- Looking for pthread_create in pthread\n",
            "-- Looking for pthread_create in pthread - found\n",
            "-- Found Threads: TRUE  \n",
            "-- Found Boost: /usr/include (found suitable version \"1.65.1\", minimum required is \"1.41.0\") found components: program_options system thread unit_test_framework chrono date_time atomic \n",
            "-- Check if compiler accepts -pthread\n",
            "-- Check if compiler accepts -pthread - yes\n",
            "-- Found ZLIB: /usr/lib/x86_64-linux-gnu/libz.so (found version \"1.2.11\") \n",
            "-- Found BZip2: /usr/lib/x86_64-linux-gnu/libbz2.so (found version \"1.0.6\") \n",
            "-- Looking for BZ2_bzCompressInit\n",
            "-- Looking for BZ2_bzCompressInit - found\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_auto_decoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_easy_encoder in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so\n",
            "-- Looking for lzma_lzma_preset in /usr/lib/x86_64-linux-gnu/liblzma.so - found\n",
            "-- Found LibLZMA: /usr/lib/x86_64-linux-gnu/liblzma.so (found version \"5.2.2\") \n",
            "-- Looking for clock_gettime in rt\n",
            "-- Looking for clock_gettime in rt - found\n",
            "-- Configuring done\n",
            "-- Generating done\n",
            "-- Build files have been written to: /content/kenlm/build\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum.cc.o\u001b[0m\n",
            "[  2%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/bignum-dtoa.cc.o\u001b[0m\n",
            "[  3%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/cached-powers.cc.o\u001b[0m\n",
            "[  5%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/diy-fp.cc.o\u001b[0m\n",
            "[  6%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/double-conversion.cc.o\u001b[0m\n",
            "[  7%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fast-dtoa.cc.o\u001b[0m\n",
            "[  8%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/fixed-dtoa.cc.o\u001b[0m\n",
            "[ 10%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/double-conversion/strtod.cc.o\u001b[0m\n",
            "[ 11%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/chain.cc.o\u001b[0m\n",
            "[ 12%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/count_records.cc.o\u001b[0m\n",
            "[ 13%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/io.cc.o\u001b[0m\n",
            "[ 15%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/line_input.cc.o\u001b[0m\n",
            "[ 16%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/multi_progress.cc.o\u001b[0m\n",
            "[ 17%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/stream/rewindable_stream.cc.o\u001b[0m\n",
            "[ 18%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/bit_packing.cc.o\u001b[0m\n",
            "[ 20%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/ersatz_progress.cc.o\u001b[0m\n",
            "[ 21%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/exception.cc.o\u001b[0m\n",
            "[ 22%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file.cc.o\u001b[0m\n",
            "[ 23%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/file_piece.cc.o\u001b[0m\n",
            "[ 25%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/float_to_string.cc.o\u001b[0m\n",
            "[ 26%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/integer_to_string.cc.o\u001b[0m\n",
            "[ 27%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/mmap.cc.o\u001b[0m\n",
            "[ 28%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/murmur_hash.cc.o\u001b[0m\n",
            "[ 30%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/parallel_read.cc.o\u001b[0m\n",
            "[ 31%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/pool.cc.o\u001b[0m\n",
            "[ 32%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/read_compressed.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/scoped.cc.o\u001b[0m\n",
            "[ 35%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/spaces.cc.o\u001b[0m\n",
            "[ 36%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/string_piece.cc.o\u001b[0m\n",
            "[ 37%] \u001b[32mBuilding CXX object util/CMakeFiles/kenlm_util.dir/usage.cc.o\u001b[0m\n",
            "[ 38%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm_util.a\u001b[0m\n",
            "[ 38%] Built target kenlm_util\n",
            "[ 40%] \u001b[32mBuilding CXX object util/CMakeFiles/probing_hash_table_benchmark.dir/probing_hash_table_benchmark_main.cc.o\u001b[0m\n",
            "[ 41%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/bhiksha.cc.o\u001b[0m\n",
            "[ 42%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/binary_format.cc.o\u001b[0m\n",
            "[ 43%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/config.cc.o\u001b[0m\n",
            "[ 45%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/lm_exception.cc.o\u001b[0m\n",
            "[ 46%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/model.cc.o\u001b[0m\n",
            "[ 47%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/quantize.cc.o\u001b[0m\n",
            "[ 48%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/read_arpa.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable ../bin/probing_hash_table_benchmark\u001b[0m\n",
            "[ 50%] Built target probing_hash_table_benchmark\n",
            "[ 51%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/arpa_io.cc.o\u001b[0m\n",
            "[ 52%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_hashed.cc.o\u001b[0m\n",
            "[ 53%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/phrase.cc.o\u001b[0m\n",
            "[ 55%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/search_trie.cc.o\u001b[0m\n",
            "[ 56%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/kenlm_filter.dir/vocab.cc.o\u001b[0m\n",
            "[ 57%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_filter.a\u001b[0m\n",
            "[ 57%] Built target kenlm_filter\n",
            "[ 58%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/sizes.cc.o\u001b[0m\n",
            "[ 60%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie.cc.o\u001b[0m\n",
            "[ 61%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/trie_sort.cc.o\u001b[0m\n",
            "[ 62%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/value_build.cc.o\u001b[0m\n",
            "[ 63%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/virtual_interface.cc.o\u001b[0m\n",
            "[ 65%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/vocab.cc.o\u001b[0m\n",
            "[ 66%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/model_buffer.cc.o\u001b[0m\n",
            "[ 67%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/print.cc.o\u001b[0m\n",
            "[ 68%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/renumber.cc.o\u001b[0m\n",
            "[ 70%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm.dir/common/size_option.cc.o\u001b[0m\n",
            "[ 71%] \u001b[32m\u001b[1mLinking CXX static library ../lib/libkenlm.a\u001b[0m\n",
            "[ 71%] Built target kenlm\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/query.dir/query_main.cc.o\u001b[0m\n",
            "[ 73%] \u001b[32mBuilding CXX object lm/CMakeFiles/fragment.dir/fragment_main.cc.o\u001b[0m\n",
            "[ 75%] \u001b[32m\u001b[1mLinking CXX executable ../bin/fragment\u001b[0m\n",
            "[ 75%] Built target fragment\n",
            "[ 76%] \u001b[32mBuilding CXX object lm/CMakeFiles/build_binary.dir/build_binary_main.cc.o\u001b[0m\n",
            "[ 77%] \u001b[32m\u001b[1mLinking CXX executable ../bin/query\u001b[0m\n",
            "[ 77%] Built target query\n",
            "[ 78%] \u001b[32mBuilding CXX object lm/CMakeFiles/kenlm_benchmark.dir/kenlm_benchmark_main.cc.o\u001b[0m\n",
            "[ 80%] \u001b[32m\u001b[1mLinking CXX executable ../bin/build_binary\u001b[0m\n",
            "[ 80%] Built target build_binary\n",
            "[ 81%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/adjust_counts.cc.o\u001b[0m\n",
            "[ 82%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/corpus_count.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/initial_probabilities.cc.o\u001b[0m\n",
            "[ 85%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/interpolate.cc.o\u001b[0m\n",
            "[ 86%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/output.cc.o\u001b[0m\n",
            "[ 87%] \u001b[32m\u001b[1mLinking CXX executable ../bin/kenlm_benchmark\u001b[0m\n",
            "[ 87%] Built target kenlm_benchmark\n",
            "[ 88%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/filter.dir/filter_main.cc.o\u001b[0m\n",
            "[ 90%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/kenlm_builder.dir/pipeline.cc.o\u001b[0m\n",
            "[ 91%] \u001b[32m\u001b[1mLinking CXX static library ../../lib/libkenlm_builder.a\u001b[0m\n",
            "[ 91%] Built target kenlm_builder\n",
            "[ 92%] \u001b[32mBuilding CXX object lm/filter/CMakeFiles/phrase_table_vocab.dir/phrase_table_vocab_main.cc.o\u001b[0m\n",
            "[ 93%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/phrase_table_vocab\u001b[0m\n",
            "[ 93%] Built target phrase_table_vocab\n",
            "[ 95%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/lmplz.dir/lmplz_main.cc.o\u001b[0m\n",
            "[ 96%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/filter\u001b[0m\n",
            "[ 96%] Built target filter\n",
            "[ 97%] \u001b[32mBuilding CXX object lm/builder/CMakeFiles/count_ngrams.dir/count_ngrams_main.cc.o\u001b[0m\n",
            "[ 98%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/lmplz\u001b[0m\n",
            "[ 98%] Built target lmplz\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable ../../bin/count_ngrams\u001b[0m\n",
            "[100%] Built target count_ngrams\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "# Download KenLM source code and compile it\n",
        "!wget -O - https://kheafield.com/code/kenlm.tar.gz |tar xz\n",
        "!mkdir kenlm/build\n",
        "%cd kenlm/build\n",
        "!cmake ..\n",
        "!make -j $(nproc)\n",
        "%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CLpCY6stC87R"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPbDZoO3C89W"
      },
      "outputs": [],
      "source": [
        "# This function is used to select the top K most frequent words from the vocab\n",
        "# list that was already prepared in the previous notebook\n",
        "\n",
        "def load_vocab(filepath, topk=None, include_freqs=False):\n",
        "    words = []\n",
        "    with open(filepath) as f1:\n",
        "        for word in f1:\n",
        "            word, freq = word.strip().split()\n",
        "            word, freq = word, int(freq)\n",
        "            words.append((word, freq))\n",
        "    words = sorted(words, key=lambda x: -x[1])\n",
        "    if not topk is None:\n",
        "        return [(word, freq) if include_freqs else word for word, freq in words][:topk]\n",
        "    return [(word, freq) if include_freqs else word for word, freq in words]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1fR5DTpC8_F"
      },
      "outputs": [],
      "source": [
        "# select top 400K frequent words from the given dataset\n",
        "unique_words = load_vocab('/content/vocab_list.txt', topk=400000, include_freqs=True)\n",
        "len(unique_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WdM7-IS4r1eS"
      },
      "outputs": [],
      "source": [
        "# Save the selected words in a file\n",
        "with open('/content/vocab_for_lm.txt', 'w') as f1:\n",
        "    for word, freq in unique_words:\n",
        "        f1.write(f'{word}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WHNvk8WvD9ja"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TiCjEEjur1gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abe05fe2-256f-405e-da5d-1a663053365d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/Clean_SaudiYoum_n_Ryiadh_text.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "tcmalloc: large alloc 2173591552 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4854fe 0x55646f4642eb 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 8694341632 bytes == 0x5564f37a2000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464308 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "=== 1/5 Counting and sorting n-grams ===\n",
            "Reading /content/Clean_SaudiYoum_n_Ryiadh_text.txt\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "tcmalloc: large alloc 2173591552 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4854fe 0x55646f4642eb 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 8694341632 bytes == 0x5564f37a2000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464308 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "*******************************************************************************************************************************************************************************************************\n",
            "*\n",
            "Unigram tokens 493489610 types 1926088\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:23113056 2:1815940224 3:3404888064 4:5447820800\n",
            "tcmalloc: large alloc 5447827456 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f4648d7 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 1815945216 bytes == 0x5565b803c000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464cdd 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 3404890112 bytes == 0x5566fa3d8000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464cdd 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "Unigram tokens 493489610 types 1926088\n",
            "=== 2/5 Calculating and sorting adjusted counts ===\n",
            "Chain sizes: 1:23113056 2:1815940224 3:3404888064 4:5447820800\n",
            "tcmalloc: large alloc 5447827456 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f4648d7 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 1815945216 bytes == 0x5565b803c000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464cdd 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "tcmalloc: large alloc 3404890112 bytes == 0x5566fa3d8000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f4d980a 0x55646f4da248 0x55646f464cdd 0x55646f450066 0x7f047253ec87 0x55646f451baa\n",
            "Statistics:\n",
            "1 400003/1926088 D1=0.644246 D2=0.996349 D3+=1.34324\n",
            "2 28190597/88592548 D1=0.762999 D2=1.09791 D3+=1.36603\n",
            "3 48388435/261881644 D1=0.869748 D2=1.19327 D3+=1.36611\n",
            "4 42838892/369986295 D1=0.849195 D2=1.40803 D3+=1.61774\n",
            "Memory estimate for binary LM:\n",
            "type      MB\n",
            "probing 2498 assuming -p 1.5\n",
            "probing 2937 assuming -r models -p 1.5\n",
            "trie    1250 without quantization\n",
            "trie     703 assuming -q 8 -b 8 quantization \n",
            "trie    1078 assuming -a 22 array pointer compression\n",
            "trie     531 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "Statistics:\n",
            "1 400003/1926088 D1=0.644246 D2=0.996349 D3+=1.34324\n",
            "2 28190597/88592548 D1=0.762999 D2=1.09791 D3+=1.36603\n",
            "3 48388435/261881644 D1=0.869748 D2=1.19327 D3+=1.36611\n",
            "4 42838892/369986295 D1=0.849195 D2=1.40803 D3+=1.61774\n",
            "Memory estimate for binary LM:\n",
            "type      MB\n",
            "probing 2498 assuming -p 1.5\n",
            "probing 2937 assuming -r models -p 1.5\n",
            "trie    1250 without quantization\n",
            "trie     703 assuming -q 8 -b 8 quantization \n",
            "trie    1078 assuming -a 22 array pointer compression\n",
            "trie     531 assuming -a 22 -q 8 -b 8 array pointer compression and quantization\n",
            "=== 3/5 Calculating and sorting initial probabilities ===\n",
            "tcmalloc: large alloc 5237637120 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f46f352 0x55646f4702ed 0x7f0473685bcd 0x7f04732546db 0x7f047263e61f\n",
            "tcmalloc: large alloc 5237637120 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f46f352 0x55646f4702ed 0x7f0473685bcd 0x7f04732546db 0x7f047263e61f\n",
            "tcmalloc: large alloc 8879677440 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f46f352 0x55646f4702ed 0x7f0473685bcd 0x7f04732546db 0x7f047263e61f\n",
            "tcmalloc: large alloc 8879677440 bytes == 0x556471ebc000 @  0x7f04743a51e7 0x55646f4ea7e2 0x55646f46f352 0x55646f4702ed 0x7f0473685bcd 0x7f04732546db 0x7f047263e61f\n",
            "Chain sizes: 1:4800036 2:451049552 3:967768700 4:1028133408\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "Chain sizes: 1:4800036 2:451049552 3:967768700 4:1028133408\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "#**********#########################################################################################\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:4800036 2:451049552 3:967768700 4:1028133408\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "\n",
            "=== 4/5 Calculating and writing order-interpolated probabilities ===\n",
            "Chain sizes: 1:4800036 2:451049552 3:967768700 4:1028133408\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "####################################################################################################\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "\n",
            "=== 5/5 Writing ARPA model ===\n",
            "----5---10---15---20---25---30---35---40---45---50---55---60---65---70---75---80---85---90---95--100\n",
            "****************************************************************************************************\n",
            "****************************************************************************************************\n",
            "Name:lmplz\tVmPeak:14306520 kB\tVmRSS:3002340 kB\tRSSMax:10680336 kB\tuser:819.529\tsys:151.112\tCPU:970.641\treal:960.138\n",
            "Name:lmplz\tVmPeak:14306520 kB\tVmRSS:3002340 kB\tRSSMax:10680336 kB\tuser:819.529\tsys:151.112\tCPU:970.641\treal:960.138\n"
          ]
        }
      ],
      "source": [
        "# Use the compiled KenLM program to build the N-Gram Language Model\n",
        "# Here, we are building a 4-gram language model (specified by the option -o 4).\n",
        "# Also, we are removing (pruning) bigrams, trigrams and quadgrams that \n",
        "# have frequency less than or equal to 1 (specified by the option --prune 0 1 1 1)\n",
        "# where the first digit represents the minimum count of unigrams, the second \n",
        "# digit represents the minimum count of bigrams, ... and so on.\n",
        "# We force the language model to have words that are only in \"vocab_for_lm.txt\"\n",
        "# file and replace other words that are not there by the unkown token \"<unk>\"\n",
        "!/content/kenlm/build/bin/lmplz -o 4 --prune 0 1 1 1 --limit_vocab_file /content/vocab_for_lm.txt < /content/Clean_SaudiYoum_n_Ryiadh_text.txt > /content/Clean_SaudiYoum_n_Ryiadh_text_lm.arpa\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddVSvFb4r1jK"
      },
      "outputs": [],
      "source": [
        "# For faster LM loading in the memory and storage efficiency, we convert the LM\n",
        "# from the standard ARPA format to a binary format\n",
        "!/content/kenlm/build/bin/build_binary /content/Clean_SaudiYoum_n_Ryiadh_text_lm.arpa /content/Clean_SaudiYoum_n_Ryiadh_text_lm.bin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u02w7VLs5EIv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fUHmO0PDm9yx"
      },
      "outputs": [],
      "source": [
        "# copy the LM and the vocab list to Google Drive to be used in the next notebook\n",
        "!cp /content/Clean_SaudiYoum_n_Ryiadh_text_lm.bin '/content/drive/My Drive/my_projects/PSU_language_models_session/lm_models'\n",
        "!cp /content/vocab_for_lm.txt '/content/drive/My Drive/my_projects/PSU_language_models_session/lm_models'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IrasKWCPCDV1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9OL2dJBSK9Va"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}